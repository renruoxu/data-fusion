{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "data_dirs = glob(\"/home/ruoxu/workspace/data/public/cifar-10-batches-py/data*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get train, test, label and reshape images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_img(im):\n",
    "    tmp = im.reshape((3,32,32))\n",
    "    im_reshape = np.zeros((32,32,3))\n",
    "    for i in range(0,3):\n",
    "        im_reshape[:,:,i] = tmp[i]\n",
    "    return im_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X =[]\n",
    "labels_train = []\n",
    "for d_dir in data_dirs:\n",
    "    with open(d_dir) as f:\n",
    "        tmp = cPickle.load(f)\n",
    "        X.append(tmp['data'])\n",
    "        labels_train.append(tmp['labels'])\n",
    "X = np.vstack(X)\n",
    "labels_train = np.concatenate(labels_train)\n",
    "print X.shape\n",
    "print labels_train.shape\n",
    "\n",
    "X_train = [reshape_img(im) for im in X]\n",
    "X_train = np.array(X_train)\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/ruoxu/workspace/data/public/cifar-10-batches-py/test_batch\") as f:\n",
    "    tmp = cPickle.load(f)\n",
    "    X = tmp['data']\n",
    "    labels_test = tmp['labels']\n",
    "labels_test = np.array(labels_test)\n",
    "print X.shape\n",
    "X_test = [reshape_img(im) for im in X]\n",
    "X_test = np.array(X_test)\n",
    "print X_test.shape\n",
    "print labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3) (5000, 32, 32, 3)\n",
      "(45000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_val,labels_train,labels_val = train_test_split(X_train, labels_train, test_size = 0.1)\n",
    "print X_train.shape,X_val.shape\n",
    "print labels_train.shape, labels_val.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"/home/ruoxu/workspace/data/public/cifar-10-batches-py/batches.meta\") as f:\n",
    "    tmp = cPickle.load(f)\n",
    "label_names = tmp['label_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Extract image feature from Decaf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import caffe\n",
    "model_file = \"/home/ruoxu/opt/caffe/models/bvlc_reference_caffenet/deploy.prototxt\"\n",
    "weights_file = \"/home/ruoxu/opt/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel\"\n",
    "#mean_file = \"/home/ruoxu/opt/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy\"\n",
    "net = caffe.Classifier(model_file, weights_file)\n",
    "                       #mean=np.load(mean_file),\n",
    "                       #channel_swap=(2,1,0),\n",
    "                       #raw_scale=255,\n",
    "                       #image_dims=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.parallel import Client\n",
    "client = Client()\n",
    "view = client.load_balanced_view()\n",
    "view.block = True\n",
    "len(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extractor(im):\n",
    "    from decaf.scripts.imagenet import DecafNet\n",
    "    f_dir = '/home/ruoxu/workspace/data/public/imagenet_pretrained/'\n",
    "    net = DecafNet(f_dir + 'imagenet.decafnet.epoch90',f_dir + 'imagenet.decafnet.meta')\n",
    "    scores = net.classify(im.astype('uint8'),center_only=True)\n",
    "    feature = net.feature('fc6_cudanet_out')\n",
    "    return feature.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time X_train_feats = view.map(feature_extractor,X_train)\n",
    "X_train_feats = np.array(X_train_feats)\n",
    "print X_train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time X_test_feats = view.map(feature_extractor,X_test)\n",
    "X_test_feats = np.array(X_test_feats)\n",
    "print X_test_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 14.6 s, total: 2min 49s\n",
      "Wall time: 2min 49s\n",
      "CPU times: user 132 ms, sys: 18 Âµs, total: 132 ms\n",
      "Wall time: 132 ms\n",
      "CPU times: user 30.7 s, sys: 479 ms, total: 31.2 s\n",
      "Wall time: 31.2 s\n",
      "CPU times: user 18.7 ms, sys: 0 ns, total: 18.7 ms\n",
      "Wall time: 18.7 ms\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "with open(\"data/train_features\") as f:\n",
    "    %time X_train_feats = cPickle.load(f)\n",
    "with open(\"data/train_labels\") as f:\n",
    "    %time labels_train = cPickle.load(f)\n",
    "with open(\"data/test_features\") as f:\n",
    "    %time X_test_feats = cPickle.load(f)\n",
    "with open(\"data/test_labels\") as f:\n",
    "    %time labels_test = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000})\n",
      "Counter({0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print Counter(labels_train)\n",
    "print Counter(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/home/ruoxu/workspace/data/public/cifar-10-batches-py/batches.meta\") as f:\n",
    "    label_names = cPickle.load(f)['label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 4096) (60000,)\n",
      "(54000, 4096) (6000, 4096)\n",
      "(54000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "# dog out\n",
    "import numpy as np\n",
    "X = np.concatenate((X_train_feats,X_test_feats))\n",
    "labels = np.concatenate((labels_train, labels_test))\n",
    "print X.shape, labels.shape\n",
    "ind_test = np.where(labels == 5)[0]\n",
    "ind_train = np.where(labels != 5)[0]\n",
    "X_train_feats = X[ind_train]\n",
    "X_test_feats = X[ind_test]\n",
    "labels_train = labels[ind_train]\n",
    "labels_test = labels[ind_test]\n",
    "print X_train_feats.shape, X_test_feats.shape\n",
    "print labels_train.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 s, sys: 83.7 ms, total: 3.3 s\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "%time model = Word2Vec.load_word2vec_format(\"/home/ruoxu/opt/word2vec/word2vec.bin\", binary=True)\n",
    "label_dict = {}\n",
    "for i in range(len(label_names)):\n",
    "    label_dict[i] = model[label_names[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 100) (6000, 100)\n"
     ]
    }
   ],
   "source": [
    "tmp_train = [label_dict[i] for i in labels_train]\n",
    "tmp_test = [label_dict[i] for i in labels_test]\n",
    "labels_train = np.array(tmp_train)\n",
    "labels_test = np.array(tmp_test)\n",
    "print labels_train.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48600, 4096) (5400, 4096)\n",
      "(48600, 100) (5400, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train_feats,X_val_feats,labels_train,labels_val = train_test_split(X_train_feats, labels_train, test_size = 0.1)\n",
    "print X_train_feats.shape,X_val_feats.shape\n",
    "print labels_train.shape, labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48600, 4096)\n",
      "(48600, 100)\n",
      "(5400, 4096)\n",
      "(5400, 100)\n"
     ]
    }
   ],
   "source": [
    "##normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_X = StandardScaler()\n",
    "ss_Y = StandardScaler()\n",
    "ss_X.fit(X_train_feats)\n",
    "ss_Y.fit(labels_train)\n",
    "X_train_feats, X_val_feats = ss_X.transform(X_train_feats), ss_X.transform(X_val_feats)\n",
    "labels_train, labels_val = ss_Y.transform(labels_train), ss_Y.transform(labels_val)\n",
    "print X_train_feats.shape\n",
    "print labels_train.shape\n",
    "print X_val_feats.shape\n",
    "print labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "save_dir = \"/home/ruoxu/workspace/x/text-image-caffe/data\"\n",
    "train_file_name = os.path.join(save_dir, \"train.h5\")\n",
    "test_file_name = os.path.join(save_dir,\"test.h5\")\n",
    "val_file_name = os.path.join(save_dir,\"val.h5\")\n",
    "\n",
    "import os\n",
    "with h5py.File(train_file_name, 'w') as f:\n",
    "    f['data'] = X_train_feats\n",
    "    f['label'] = labels_train.astype(np.float32)\n",
    "with h5py.File(test_file_name, 'w') as f:\n",
    "    f['data'] = X_test_feats\n",
    "    f['label'] = labels_test.astype(np.float32)\n",
    "with h5py.File(val_file_name,\"w\") as f:\n",
    "    f['data'] = X_val_feats\n",
    "    f['label'] = labels_val.astype(np.float32)\n",
    "with open(os.path.join(save_dir, \"train.txt\"), 'w') as f:\n",
    "    f.write(train_file_name + '\\n')\n",
    "with open(os.path.join(save_dir,\"test.txt\"), 'w') as f:\n",
    "    f.write(test_file_name + '\\n')\n",
    "with open(os.path.join(save_dir,\"val.txt\"), 'w') as f:\n",
    "    f.write(val_file_name + '\\n')\n",
    "with open(os.path.join(save_dir,\"x_normalizer\"),\"w\") as f:\n",
    "    cPickle.dump(ss_X,f)\n",
    "with open(os.path.join(save_dir,\"y_normalizer\"),\"w\") as f:\n",
    "    cPickle.dump(ss_Y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
